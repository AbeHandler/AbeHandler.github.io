<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-05-18T08:56:00-04:00</updated><id>http://localhost:4000/</id><title type="html">Abe Handler</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies</title><link href="http://localhost:4000/syntax/lstms/2018/05/15/assessing_the_abililty_of_lstms.html" rel="alternate" type="text/html" title="Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies" /><published>2018-05-15T00:00:00-04:00</published><updated>2018-05-15T00:00:00-04:00</updated><id>http://localhost:4000/syntax/lstms/2018/05/15/assessing_the_abililty_of_lstms</id><content type="html" xml:base="http://localhost:4000/syntax/lstms/2018/05/15/assessing_the_abililty_of_lstms.html">&lt;ul&gt;
  &lt;li&gt;Title: Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies &lt;a href=&quot;https://arxiv.org/pdf/1611.01368.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Authors: Tal Linzen, Emmanuel Dupoux and Yoav Goldberg&lt;/li&gt;
  &lt;li&gt;Venue: TAACL (2016)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;LSTMs are sequence models, which represent natural language as an incremental
series of symbols. This is different from hierarchical models (e.g. PCFGs) which
represent language using nested structures. This very straightforward and well-executed
paper asks: to what extent can LSTM sequence models can learn syntactic dependencies?
Such dependencies might be more obviously encoded with hierarchical, rather than sequence, representations.&lt;/p&gt;

&lt;p&gt;Because LTSMs are often said to
learn long-range relationships between words (syntactic or otherwise), understanding
their capacity to learn particular syntactic constraints would help illuminate
both the strengths and weaknesses of using LSTMs for language technologies.&lt;/p&gt;

&lt;p&gt;The authors focus
on a particular syntactic dependency, subject–verb agreement, which is “typically regarded as
evidence for hierarchical structure in human language”. The paper tests if RNNs
can represent this dependency between subject and verb.&lt;/p&gt;

&lt;p&gt;More concretely, the authors introduce a new “number prediction” task in which
a LSTM is shown a sentence of words up to a given verb. The network is then trained to predict if the verb is singular
or plural, using a logistic regression classifier over features from the final hidden state of the RNN.&lt;/p&gt;

&lt;p&gt;In English, if the subject of a 3rd person present tense verb is singular, the
verb must be singular. If the subject is plural, the verb must be plural. For instance,
we say that “the key&lt;strong&gt;s&lt;/strong&gt; &lt;strong&gt;are&lt;/strong&gt; on the table” and “the key &lt;strong&gt;is&lt;/strong&gt; on the table.”
The subject and verb must agree.&lt;/p&gt;

&lt;p&gt;The primary empirical contribution of this paper is testing the performance of
LSTMs on this number prediction task. The authors automatically generate a corpus
of more than a million number prediction problems from English Wikipedia (using
dependency parses to find correct answers) and then train a traditional LSTM
to read in an input sequence and then predict the number of the verb.
They also test a baseline version of this classifier
which only uses a sequence of preceding nouns, without access to function words.&lt;/p&gt;

&lt;p&gt;In general, the authors find that LSTMs perform well at this task, achieving an error rate of only .83%.&lt;/p&gt;

&lt;p&gt;However, there are many nuances to this finding.
In some cases, there may be many intervening words
between the subject and the verb. For instance, we might say: “the keys, which
my friend left for me in my &lt;em&gt;house&lt;/em&gt; before his &lt;em&gt;trip&lt;/em&gt; to &lt;em&gt;Boston&lt;/em&gt;, are on the table”.
Here the subject &lt;strong&gt;keys&lt;/strong&gt; agrees with the verb &lt;strong&gt;are&lt;/strong&gt;, even though there are many
intervening nouns (&lt;em&gt;house&lt;/em&gt;, &lt;em&gt;trip&lt;/em&gt;, &lt;em&gt;Boston&lt;/em&gt;). A sequence model which learns syntactic dependencies
would be able to ascertain that &lt;em&gt;keys&lt;/em&gt; should agree with &lt;em&gt;are&lt;/em&gt;, even with such intervening
nouns. The paper calls such nouns “agreement attractors”, citing &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/2001615&quot;&gt;Bock and Miller, 1991&lt;/a&gt;). The paper finds that the error rate increases with the number of agreement attractors. This makes sense, as it is more challenging for the LSTM to determine which of the preceding nouns determines the number
of the upcoming verb. The authors also find a higher error rate for the noun-only model, which suggests that LSTMs make use of grammatical function words to predict a
verb’s number.&lt;/p&gt;

&lt;p&gt;The authors also perform PCA on the word vectors from the model and then assigning
each vector with its expected (most common) POS tag from the corpus. The PCA
results show two distinct clusters in the low-dimensional representation,
corresponding to singular and plural nouns. This provides some intuition about why the LSTM appears to have at least some capacity to represent the information necessary for correctly resolving syntactic dependencies: singular and plural nouns are more likely to appear in certain regions of vector space.&lt;/p&gt;

&lt;p&gt;The authors also report results for several alternative training methods: one in which
the network is allowed to see the form of a verb before making a prediction
(this should make the network’s job easier by allowing semantic matching between
subject and verb), one in which the network decides if a sentence is grammatical
and one in which the network predicts the verb with a standard language model (using the relative probabilities of the singular and plural forms of the verb).
Notably, the language model, which receives no explicit symbol for verb number,
performs worse than systems directly trained on predicting the form of the subsequent verb. This might mean that standard neural network LMs need
explicit training signals to learn syntactic dependencies.&lt;/p&gt;

&lt;p&gt;The authors conclude their paper by discussing and summarizing their results.
They point out that LSTMs are able to learn one particular syntactic
dependency with explicit supervision, but that standard language models have higher
error rates for this task without such supervision. One extension of this research would be to then modify LM training to make use of syntactic supervision.&lt;/p&gt;</content><author><name></name></author><summary type="html">Title: Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies PDF Authors: Tal Linzen, Emmanuel Dupoux and Yoav Goldberg Venue: TAACL (2016)</summary></entry><entry><title type="html">Sentence Reduction for Automatic Text Summarization</title><link href="http://localhost:4000/summarization/compression/2018/01/11/sentence-redution-for-automatic-text-summarization.html" rel="alternate" type="text/html" title="Sentence Reduction for Automatic Text Summarization" /><published>2018-01-11T12:40:53-05:00</published><updated>2018-01-11T12:40:53-05:00</updated><id>http://localhost:4000/summarization/compression/2018/01/11/sentence-redution-for-automatic-text-summarization</id><content type="html" xml:base="http://localhost:4000/summarization/compression/2018/01/11/sentence-redution-for-automatic-text-summarization.html">&lt;ul&gt;
  &lt;li&gt;Title: Sentence Reduction for Automatic Text Summarization &lt;a href=&quot;http://delivery.acm.org/10.1145/980000/974190/p310-jing.pdf?ip=74.105.10.86&amp;amp;id=974190&amp;amp;acc=OPEN&amp;amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;amp;CFID=850146679&amp;amp;CFTOKEN=43433700&amp;amp;__acm__=1515685122_a0b141d0232617369741d8940165acb6&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Authors: Hongyan Jing&lt;/li&gt;
  &lt;li&gt;Venue: Applied Natural Language Processing Conference (2000)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nutshell&quot;&gt;Nutshell&lt;/h3&gt;

&lt;p&gt;This is a very early sentence compression paper from Hongyan Jing, a student of &lt;a href=&quot;http://www.cs.columbia.edu/~kathy/&quot;&gt;Kathleen McKeown&lt;/a&gt;. It was really interesting for me to read because I’ve looked at a bunch of recent work on the same topic.&lt;/p&gt;

&lt;p&gt;To shorten a sentence, Jing does the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;assigns an &lt;strong&gt;importance score&lt;/strong&gt; using WordNet to each phrase in the sentence.&lt;/li&gt;
  &lt;li&gt;uses a supervised corpus of summary–document pairs to determine the probability of pruning a constituent subtree of a given type, conditioned on its parent node.&lt;/li&gt;
  &lt;li&gt;uses a constituent parser and lexical resource to identify mandatory grammatical components, guided by manual rules.&lt;/li&gt;
  &lt;li&gt;traverses the constituent parse tree from top to bottom, pruning subtrees which (1) are not grammaticality necessary (2) have a high probably of removal by a human annotator and (3) have low importance.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Jing evaluates her method using a custom metric, the ‘‘success rate’’, which measures the degree of overlap between a computer and a human annotator.&lt;/p&gt;

&lt;h3 id=&quot;discussion&quot;&gt;Discussion&lt;/h3&gt;

&lt;p&gt;One thing which is striking is the deep similarity between this work and later approaches to sentence compression. The core concerns in Jing (2000), &lt;a href=&quot;http://www.aclweb.org/anthology/W08-1105&quot;&gt;Filipova and Strube&lt;/a&gt; (2008) and &lt;a href=&quot;http://www.jair.org/papers/paper2433.html&quot;&gt;Clarke and Lapata&lt;/a&gt; (2010) are quite similar: the goal is to retain ‘‘important’’ portions of a source sentence while retaining grammaticality. The techniques for determining how to automatically meet these criteria have shifted, but in many ways the basic ideas are the same. Of course, &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43852.pdf&quot;&gt;recent&lt;/a&gt; sentence compression &lt;a href=&quot;/summarization/neuralnets/2018/01/10/neural-summarization-by-extracting-sentences-and-words.html&quot;&gt;papers&lt;/a&gt; use neural networks to try and replicate these aims in a “data-driven” fashion.&lt;/p&gt;

&lt;p&gt;Based on 20 years of research, it seems like the sentence compression agenda in NLP might be &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41393.pdf&quot;&gt;more data&lt;/a&gt; + better modeling = closer automated replication of human summarization decisions. (As measured by ROUGE score or Pyramid or some other metric).&lt;/p&gt;

&lt;p&gt;This paradigm is common across NLP. But for summarization, the approach often annoys me: it seems obvious that different kinds of users will have different information needs. Query-focused summarization is supposed to address this issue, but I’m sort of dubious that there even exists a “gold standard”, &lt;em&gt;perfect&lt;/em&gt; summary for a given query. There seem to be deep limitations to this “annotate and model” paradigm, at least for sentence compression.&lt;/p&gt;</content><author><name></name></author><summary type="html">Title: Sentence Reduction for Automatic Text Summarization PDF Authors: Hongyan Jing Venue: Applied Natural Language Processing Conference (2000)</summary></entry><entry><title type="html">Neural Summarization by Extracting Sentences and Words</title><link href="http://localhost:4000/summarization/neuralnets/2018/01/10/neural-summarization-by-extracting-sentences-and-words.html" rel="alternate" type="text/html" title="Neural Summarization by Extracting Sentences and Words" /><published>2018-01-10T12:40:53-05:00</published><updated>2018-01-10T12:40:53-05:00</updated><id>http://localhost:4000/summarization/neuralnets/2018/01/10/neural-summarization-by-extracting-sentences-and-words</id><content type="html" xml:base="http://localhost:4000/summarization/neuralnets/2018/01/10/neural-summarization-by-extracting-sentences-and-words.html">&lt;ul&gt;
  &lt;li&gt;Title: Neural Summarization by Extracting Sentences and Words &lt;a href=&quot;https://arxiv.org/pdf/1603.07252.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Authors: Jianpeng Cheng and Mirella Lapata&lt;/li&gt;
  &lt;li&gt;Venue: ACL 2016&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;I found this paper on neural summarization while searching for neural network approaches
to sentence compression. Mirella Lapata has co-authored &lt;a href=&quot;http://www.jair.org/media/2433/live-2433-3731-jair.pdf&quot;&gt;influential papers&lt;/a&gt;
on compression using classical methods, so I was curious to read his deep learning approach.
The paper also uses &lt;a href=&quot;https://arxiv.org/abs/1506.03134&quot;&gt;&lt;em&gt;pointer networks&lt;/em&gt;&lt;/a&gt;, which I have seen in
&lt;a href=&quot;https://arxiv.org/abs/1704.04368&quot;&gt;other recent&lt;/a&gt; summarization papers, another reason I chose to read this one in depth.&lt;/p&gt;

&lt;p&gt;According to Cheng and Lapata (sec 7), the main contributions of the paper are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;offering a hierarchical, neural model which creates a summary by choosing words and sentences, which they say reflects “the nature of the summarization task”.&lt;/li&gt;
  &lt;li&gt;generation by extraction, by which they mean generating output, using words from a single document (rather than the vocabulary of the whole corpus).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The paper is a nice synthesis and extension of much recent work on neural summarization using sequence-to-sequence models, such as &lt;a href=&quot;https://arxiv.org/pdf/1509.00685.pdf&quot;&gt;Rush, Chopra, Weston (2015)&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;nutshell&quot;&gt;Nutshell&lt;/h3&gt;

&lt;p&gt;The authors collect gold standard summaries by downloading article/highlight summary summary pairs from the DailyMail, &lt;a href=&quot;https://arxiv.org/pdf/1606.02858.pdf&quot;&gt;a common dataset&lt;/a&gt;. They then use a series of hand-written rules to identify which sentences from an article ‘‘match a highlight’’. They also filter articles with highlights containing words which are &lt;em&gt;not&lt;/em&gt; drawn from a given document, as their model generates ‘‘by extraction’’.&lt;/p&gt;

&lt;p&gt;Using this DailyMail dataset for supervision, the authors present a somewhat complex, multi-component neural network model which:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;uses a convolutional neural network (CNN) to create a sentence embedding for each sentence in the input document&lt;/li&gt;
  &lt;li&gt;feeds the sequence of sentence embeddings into an LSTM to create a document embedding&lt;/li&gt;
  &lt;li&gt;decodes the document embedding timestep-by-timestep&lt;/li&gt;
  &lt;li&gt;uses the state of the decoder as input to a &lt;strong&gt;hierarchical&lt;/strong&gt; attention mechanism over first (a) each sentence in the document and then (b) each word type in the document to finally generate a word for the output sequence.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;They then evaluate their model against competing approaches using ROUGE scores on the &lt;a href=&quot;http://duc.nist.gov/&quot;&gt;DUC 2002&lt;/a&gt; and DailyMail datasets.&lt;/p&gt;

&lt;p&gt;The authors argue that that step 4 is a hybrid of extractive and true abstractive summarization. In many respects, step 4 (section 4.3 in the paper) represents the major contribution of the work.&lt;/p&gt;

&lt;h3 id=&quot;comments&quot;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;In section 4.3, the authors present a model which generates a word in a summary instead of a label for each sentence in the input sequence. Doesn’t this then imply that the summary must have as many word tokens as the number of sentences in the document? If so, this is a sort of strange constraint for a model. If the pitch for this approach is that it offers a model which reflects “the nature of the summarization task”, this seems like a significant limitation.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Title: Neural Summarization by Extracting Sentences and Words PDF Authors: Jianpeng Cheng and Mirella Lapata Venue: ACL 2016</summary></entry></feed>