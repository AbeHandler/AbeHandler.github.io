{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPybMPmEJvTTyfkdjpIsqwR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbeHandler/AbeHandler.github.io/blob/master/sa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The plan\n",
        "\n",
        "1. Compute sa for each shard\n",
        "2. Merge them w/ a mem map low memory merge\n",
        "3. Shard the big SA. The sequences that are similar will go in the same shard\n",
        "4. Search those shards in parallel"
      ],
      "metadata": {
        "id": "tb-J6SYpMNfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydivsufsort import divsufsort, kasai\n",
        "\n",
        "s = \"aabaa\"\n",
        "s1 = f\"{s}document9stuff\"\n",
        "s2 = f\"{s}lorem$\"\n",
        "text = s1 + s2  # \"aabaa document stuff$aabaa lorem\"\n",
        "\n",
        "# Compute SA and LCP\n",
        "sa = divsufsort(text)\n",
        "lcp = kasai(text, sa)\n",
        "\n",
        "THRESHOLD = 5\n",
        "\n",
        "# Display entries where LCP >= 2 and show the two common characters\n",
        "print(f\"{'i':>2} {'SA[i]':>5} {'SA[i-1]':>7} {'LCP[i]':>7}  {f'Common ({THRESHOLD} chars)':>20}  {'Suffix_i':>12}  {'Suffix_prev'}\")\n",
        "print(\"-\" * 100)\n",
        "for i in range(1, len(sa)):\n",
        "    if lcp[i] >= THRESHOLD:\n",
        "        pos_i = sa[i]\n",
        "        pos_prev = sa[i-1]\n",
        "        common = text[pos_i:pos_i + THRESHOLD]\n",
        "        suffix_i = text[pos_i:]\n",
        "        suffix_prev = text[pos_prev:]\n",
        "        print(f\"{i:2} {pos_i:5} {pos_prev:7} {lcp[i]:7}  {common!r:20}  {suffix_i!r:12}  {suffix_prev!r}\")\n",
        "\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "w5Dr2WoF-G0H",
        "outputId": "16980a04-ad48-4cc3-f649-dd2ef39b8873"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " i SA[i] SA[i-1]  LCP[i]      Common (5 chars)      Suffix_i  Suffix_prev\n",
            "----------------------------------------------------------------------------------------------------\n",
            " 2     0      13       5  'aabaa'               'aabaadocument9stuffaabaalorem$'  '9stuffaabaalorem$'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aabaadocument9stuffaabaalorem$'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mmap\n",
        "\n",
        "sa1 = divsufsort(s1).astype(np.uint64)\n",
        "sa1.tofile(\"sa1.bin\")\n",
        "\n",
        "sa2 = divsufsort(s2).astype(np.uint64)\n",
        "sa2.tofile(\"sa2.bin\")\n",
        "\n",
        "\n",
        "sa1_mm = np.memmap(\"sa1.bin\", dtype=np.uint64, mode=\"r\")\n",
        "sa2_mm = np.memmap(\"sa2.bin\", dtype=np.uint64, mode=\"r\")\n",
        "\n",
        "# Write the concatenated text to disk for mmap\n",
        "with open(\"text.bin\", \"wb\") as f:\n",
        "    f.write((s1 + s2).encode())\n",
        "\n",
        "# Memory-map the text\n",
        "f_text = open(\"text.bin\", \"rb\")\n",
        "text_mm = mmap.mmap(f_text.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "\n",
        "# 4) Merge the two suffix arrays without loading fully into RAM\n",
        "len1 = len(s1)\n",
        "n1, n2 = sa1_mm.shape[0], sa2_mm.shape[0]\n",
        "merged_len = n1 + n2\n",
        "\n",
        "merged_sa = np.memmap(\"merged_sa.bin\", dtype=np.uint64, mode=\"w+\", shape=(merged_len,))\n",
        "\n",
        "i = j = k = 0\n",
        "while i < n1 and j < n2:\n",
        "    idx1 = int(sa1_mm[i])\n",
        "    idx2 = int(sa2_mm[j]) + len1\n",
        "    # compare suffixes via mmap\n",
        "    if text_mm[idx1:] < text_mm[idx2:]:\n",
        "        merged_sa[k] = idx1\n",
        "        i += 1\n",
        "    else:\n",
        "        merged_sa[k] = idx2\n",
        "        j += 1\n",
        "    k += 1\n",
        "\n",
        "# drain remainders\n",
        "while i < n1:\n",
        "    merged_sa[k] = int(sa1_mm[i])\n",
        "    i += 1; k += 1\n",
        "while j < n2:\n",
        "    merged_sa[k] = int(sa2_mm[j]) + len1\n",
        "    j += 1; k += 1\n",
        "\n",
        "merged_sa.flush()\n",
        "print(\"Merged suffix array written to 'merged_sa.bin'\")\n",
        "\n",
        "merged_sa = np.fromfile(\"merged_sa.bin\", dtype=np.uint64)\n",
        "merged_sa_correct = divsufsort(s1 + s2).astype(np.uint64)"
      ],
      "metadata": {
        "id": "CCZ7RXllJnUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b0addb-2aa7-49a4-b136-bc8cea3530d9"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged suffix array written to 'merged_sa.bin'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert (merged_sa_correct == merged_sa).all()"
      ],
      "metadata": {
        "id": "wd38sAjQxoXq"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "output_dir = Path(\"sharded_sa\")\n",
        "\n",
        "if output_dir.exists():\n",
        "    shutil.rmtree(output_dir)\n",
        "\n",
        "filepath = \"merged_sa.bin\"\n",
        "dtype = np.uint64\n",
        "N = 1  # number of shards\n",
        "\n",
        "output_dir = Path(\"sharded_sa\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Open as memmap (read-only)\n",
        "sa = np.memmap(filepath, dtype=dtype, mode=\"r\")\n",
        "total_len = len(sa)\n",
        "\n",
        "# Compute shard boundaries\n",
        "shard_sizes = np.array_split(np.arange(total_len), N)\n",
        "\n",
        "# Save each shard without loading entire array\n",
        "for i, idxs in enumerate(shard_sizes):\n",
        "    shard = sa[idxs[0]: idxs[-1] + 1]  # slice view, not copy\n",
        "    shard.tofile(output_dir / f\"shard_{i:03d}.bin\")\n"
      ],
      "metadata": {
        "id": "hLCu7mdSt1Tg"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_suffix(f, pos, max_len):\n",
        "    f.seek(pos)\n",
        "    return f.read(max_len)  # truncate comparison for performance\n",
        "\n",
        "def compute_lcp_for_shard(sa, f_text, max_prefix_len=512):\n",
        "    lcp = np.zeros(len(sa), dtype=np.uint32)\n",
        "    for i in range(1, len(sa)):\n",
        "        suffix1 = read_suffix(f_text, sa[i - 1], max_prefix_len)\n",
        "        suffix2 = read_suffix(f_text, sa[i], max_prefix_len)\n",
        "\n",
        "        # Debug: show first byte (or decode if safe)\n",
        "        # print(f\"{i}: {suffix1[:10]!r} vs {suffix2[:10]!r}\")\n",
        "\n",
        "        match_len = 0\n",
        "        for b1, b2 in zip(suffix1, suffix2):\n",
        "            if b1 != b2:\n",
        "                break\n",
        "            match_len += 1\n",
        "\n",
        "        lcp[i] = match_len\n",
        "    return lcp\n",
        "\n",
        "\n",
        "with open(\"text.bin\", \"rb\") as f_text:\n",
        "    sa = np.fromfile(\"sharded_sa/shard_000.bin\", dtype=np.uint64)\n",
        "\n",
        "sa2 = divsufsort(text)\n",
        "sa = merged_sa\n",
        "with open(\"text.bin\", \"rb\") as f_text:\n",
        "    sa_shard = np.fromfile(\"sharded_sa/shard_000.bin\", dtype=np.uint64).astype(np.int32)\n",
        "    lcp = compute_lcp_for_shard(sa, f_text)"
      ],
      "metadata": {
        "id": "x4qleroQvSBv"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display entries where LCP >= 2 and show the two common characters\n",
        "print(f\"{'i':>2} {'SA[i]':>5} {'SA[i-1]':>7} {'LCP[i]':>7}  {f'Common ({THRESHOLD} chars)':>20}  {'Suffix_i':>12}  {'Suffix_prev'}\")\n",
        "print(\"-\" * 100)\n",
        "for i in range(1, len(sa_shard)):\n",
        "    if lcp[i] >= THRESHOLD:\n",
        "        pos_i = sa[i]\n",
        "        pos_prev = sa[i-1]\n",
        "        common = text[pos_i:pos_i + THRESHOLD]\n",
        "        suffix_i = text[pos_i:]\n",
        "        suffix_prev = text[pos_prev:]\n",
        "        print(f\"{i:2} {pos_i:5} {pos_prev:7} {lcp[i]:7}  {common!r:20}  {suffix_i!r:12}  {suffix_prev!r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXcMmMIYvqGS",
        "outputId": "94775535-2bab-4eeb-d156-73c0a59b2fc4"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " i SA[i] SA[i-1]  LCP[i]      Common (5 chars)      Suffix_i  Suffix_prev\n",
            "----------------------------------------------------------------------------------------------------\n",
            " 3    19       0       5  'aabaa'               'aabaalorem$'  'aabaadocument9stuffaabaalorem$'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: blank class called suffix manager\n",
        "\n",
        "class suffix_manager:\n",
        "  pass"
      ],
      "metadata": {
        "id": "kluOTsAZz3HB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}