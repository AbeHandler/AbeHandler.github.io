{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMe0wGE3fjE+ADvCn9Bfozs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbeHandler/AbeHandler.github.io/blob/master/sa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The plan\n",
        "\n",
        "1. Compute sa for each shard\n",
        "2. Merge them w/ a mem map low memory merge\n",
        "3. Shard the big SA. The sequences that are similar will go in the same shard\n",
        "4. Search those shards in parallel"
      ],
      "metadata": {
        "id": "tb-J6SYpMNfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydivsufsort import divsufsort, kasai\n",
        "\n",
        "s = \"aabaa\"\n",
        "s1 = f\"{s}document9stuff\"\n",
        "s2 = f\"{s}lorem$\"\n",
        "text = s1 + s2  # \"aabaa document stuff$aabaa lorem\"\n",
        "\n",
        "# Compute SA and LCP\n",
        "sa = divsufsort(text)\n",
        "lcp = kasai(text, sa)\n",
        "\n",
        "THRESHOLD = 5\n",
        "\n",
        "# Display entries where LCP >= 2 and show the two common characters\n",
        "print(f\"{'i':>2} {'SA[i]':>5} {'SA[i-1]':>7} {'LCP[i]':>7}  {f'Common ({THRESHOLD} chars)':>20}  {'Suffix_i':>12}  {'Suffix_prev'}\")\n",
        "print(\"-\" * 100)\n",
        "for i in range(1, len(sa)):\n",
        "    if lcp[i] >= THRESHOLD:\n",
        "        pos_i = sa[i]\n",
        "        pos_prev = sa[i-1]\n",
        "        common = text[pos_i:pos_i + THRESHOLD]\n",
        "        suffix_i = text[pos_i:]\n",
        "        suffix_prev = text[pos_prev:]\n",
        "        print(f\"{i:2} {pos_i:5} {pos_prev:7} {lcp[i]:7}  {common!r:20}  {suffix_i!r:12}  {suffix_prev!r}\")\n",
        "\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "w5Dr2WoF-G0H",
        "outputId": "49d1aa8c-6bc3-40a5-9aad-dd8df80417c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " i SA[i] SA[i-1]  LCP[i]      Common (5 chars)      Suffix_i  Suffix_prev\n",
            "----------------------------------------------------------------------------------------------------\n",
            " 2     0      13       5  'aabaa'               'aabaadocument9stuffaabaalorem$'  '9stuffaabaalorem$'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aabaadocument9stuffaabaalorem$'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mmap\n",
        "\n",
        "sa1 = divsufsort(s1).astype(np.uint64)\n",
        "sa1.tofile(\"sa1.bin\")\n",
        "\n",
        "sa2 = divsufsort(s2).astype(np.uint64)\n",
        "sa2.tofile(\"sa2.bin\")\n",
        "\n",
        "\n",
        "sa1_mm = np.memmap(\"sa1.bin\", dtype=np.uint64, mode=\"r\")\n",
        "sa2_mm = np.memmap(\"sa2.bin\", dtype=np.uint64, mode=\"r\")\n",
        "\n",
        "# Write the concatenated text to disk for mmap\n",
        "with open(\"text.bin\", \"wb\") as f:\n",
        "    f.write((s1 + s2).encode())\n",
        "\n",
        "# Memory-map the text\n",
        "f_text = open(\"text.bin\", \"rb\")\n",
        "text_mm = mmap.mmap(f_text.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "\n",
        "# 4) Merge the two suffix arrays without loading fully into RAM\n",
        "len1 = len(s1)\n",
        "n1, n2 = sa1_mm.shape[0], sa2_mm.shape[0]\n",
        "merged_len = n1 + n2\n",
        "\n",
        "merged_sa = np.memmap(\"merged_sa.bin\", dtype=np.uint64, mode=\"w+\", shape=(merged_len,))\n",
        "\n",
        "i = j = k = 0\n",
        "while i < n1 and j < n2:\n",
        "    idx1 = int(sa1_mm[i])\n",
        "    idx2 = int(sa2_mm[j]) + len1\n",
        "    # compare suffixes via mmap\n",
        "    if text_mm[idx1:] < text_mm[idx2:]:\n",
        "        merged_sa[k] = idx1\n",
        "        i += 1\n",
        "    else:\n",
        "        merged_sa[k] = idx2\n",
        "        j += 1\n",
        "    k += 1\n",
        "\n",
        "# drain remainders\n",
        "while i < n1:\n",
        "    merged_sa[k] = int(sa1_mm[i])\n",
        "    i += 1; k += 1\n",
        "while j < n2:\n",
        "    merged_sa[k] = int(sa2_mm[j]) + len1\n",
        "    j += 1; k += 1\n",
        "\n",
        "merged_sa.flush()\n",
        "print(\"Merged suffix array written to 'merged_sa.bin'\")\n",
        "\n",
        "merged_sa = np.fromfile(\"merged_sa.bin\", dtype=np.uint64)\n",
        "merged_sa_correct = divsufsort(s1 + s2).astype(np.uint64)"
      ],
      "metadata": {
        "id": "CCZ7RXllJnUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210fd923-3b7d-463d-fa5e-9c42d55b6371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged suffix array written to 'merged_sa.bin'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert (merged_sa_correct == merged_sa).all()"
      ],
      "metadata": {
        "id": "wd38sAjQxoXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "output_dir = Path(\"sharded_sa\")\n",
        "\n",
        "if output_dir.exists():\n",
        "    shutil.rmtree(output_dir)\n",
        "\n",
        "filepath = \"merged_sa.bin\"\n",
        "dtype = np.uint64\n",
        "N = 1  # number of shards\n",
        "\n",
        "output_dir = Path(\"sharded_sa\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Open as memmap (read-only)\n",
        "sa = np.memmap(filepath, dtype=dtype, mode=\"r\")\n",
        "total_len = len(sa)\n",
        "\n",
        "# Compute shard boundaries\n",
        "shard_sizes = np.array_split(np.arange(total_len), N)\n",
        "\n",
        "# Save each shard without loading entire array\n",
        "for i, idxs in enumerate(shard_sizes):\n",
        "    shard = sa[idxs[0]: idxs[-1] + 1]  # slice view, not copy\n",
        "    shard.tofile(output_dir / f\"shard_{i:03d}.bin\")\n"
      ],
      "metadata": {
        "id": "hLCu7mdSt1Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_suffix(f, pos, max_len):\n",
        "    f.seek(pos)\n",
        "    return f.read(max_len)  # truncate comparison for performance\n",
        "\n",
        "def compute_lcp_for_shard(sa, f_text, max_prefix_len=512):\n",
        "    lcp = np.zeros(len(sa), dtype=np.uint32)\n",
        "    for i in range(1, len(sa)):\n",
        "        suffix1 = read_suffix(f_text, sa[i - 1], max_prefix_len)\n",
        "        suffix2 = read_suffix(f_text, sa[i], max_prefix_len)\n",
        "\n",
        "        # Debug: show first byte (or decode if safe)\n",
        "        # print(f\"{i}: {suffix1[:10]!r} vs {suffix2[:10]!r}\")\n",
        "\n",
        "        match_len = 0\n",
        "        for b1, b2 in zip(suffix1, suffix2):\n",
        "            if b1 != b2:\n",
        "                break\n",
        "            match_len += 1\n",
        "\n",
        "        lcp[i] = match_len\n",
        "    return lcp\n",
        "\n",
        "\n",
        "with open(\"text.bin\", \"rb\") as f_text:\n",
        "    sa = np.fromfile(\"sharded_sa/shard_000.bin\", dtype=np.uint64)\n",
        "\n",
        "sa2 = divsufsort(text)\n",
        "sa = merged_sa\n",
        "with open(\"text.bin\", \"rb\") as f_text:\n",
        "    sa_shard = np.fromfile(\"sharded_sa/shard_000.bin\", dtype=np.uint64).astype(np.int32)\n",
        "    lcp = compute_lcp_for_shard(sa, f_text)"
      ],
      "metadata": {
        "id": "x4qleroQvSBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display entries where LCP >= 2 and show the two common characters\n",
        "print(f\"{'i':>2} {'SA[i]':>5} {'SA[i-1]':>7} {'LCP[i]':>7}  {f'Common ({THRESHOLD} chars)':>20}  {'Suffix_i':>12}  {'Suffix_prev'}\")\n",
        "print(\"-\" * 100)\n",
        "for i in range(1, len(sa_shard)):\n",
        "    if lcp[i] >= THRESHOLD:\n",
        "        pos_i = sa[i]\n",
        "        pos_prev = sa[i-1]\n",
        "        common = text[pos_i:pos_i + THRESHOLD]\n",
        "        suffix_i = text[pos_i:]\n",
        "        suffix_prev = text[pos_prev:]\n",
        "        print(f\"{i:2} {pos_i:5} {pos_prev:7} {lcp[i]:7}  {common!r:20}  {suffix_i!r:12}  {suffix_prev!r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXcMmMIYvqGS",
        "outputId": "01b2416a-75b8-406a-ed46-c41a9ad8b44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " i SA[i] SA[i-1]  LCP[i]      Common (5 chars)      Suffix_i  Suffix_prev\n",
            "----------------------------------------------------------------------------------------------------\n",
            " 3    19       0       5  'aabaa'               'aabaalorem$'  'aabaadocument9stuffaabaalorem$'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "string_inp = \"banana$\"\n",
        "int_inp = np.unique(np.array(list(string_inp)), return_inverse=True)[1]\n",
        "int_suffix_array = divsufsort(int_inp)\n",
        "int_lcp_array = kasai(int_inp.astype(np.int32), int_suffix_array)\n",
        "print(int_suffix_array, int_lcp_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuwjSjQgsBJk",
        "outputId": "7828d545-7b04-48d1-da3c-dee05d8cb765"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 5 3 1 0 4 2] [0 1 3 0 0 2 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(int_inp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzRnY8SlsLpP",
        "outputId": "020c0d20-c32e-41b4-9922-a595fe47456c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "enc.encode(\"banana$\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4xhidrfs8HJ",
        "outputId": "8d4bcdcd-caa3-40f3-9bf6-e41ddcc8ce82"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3820, 2271, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tiktoken\n",
        "from pydivsufsort import divsufsort, kasai\n",
        "\n",
        "int_inp = np.asarray([1,2,3,1, 2], dtype=np.int32)\n",
        "\n",
        "int_suffix_array = divsufsort(int_inp)\n",
        "int_lcp_array     = kasai(int_inp, int_suffix_array)\n",
        "\n",
        "i = 0                            # this is the LCP index you were inspecting\n",
        "idx1 = int_suffix_array[i]       # SA[0] == 3\n",
        "idx2 = int_suffix_array[i+1]     # SA[1] == 0\n",
        "\n",
        "print(\"suffix1:\", int_inp[idx1:].tolist())  # [1, 2]\n",
        "print(\"suffix2:\", int_inp[idx2:].tolist())  # [1, 2, 3, 1, 2]\n",
        "print(\"lcp[0]  :\", int_lcp_array[0])        # 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DGKzzIJtONO",
        "outputId": "461e4162-0c36-49ee-fb9a-4ecf634a8823"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "suffix1: [1, 2]\n",
            "suffix2: [1, 2, 3, 1, 2]\n",
            "lcp[0]  : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tiktoken\n",
        "from pydivsufsort import divsufsort, kasai\n",
        "\n",
        "int_inp = np.asarray([1,2,3,1, 2], dtype=np.int32)\n",
        "\n",
        "int_suffix_array = divsufsort(int_inp)\n",
        "int_lcp_array     = kasai(int_inp, int_suffix_array)\n",
        "\n",
        "i = 0                            # this is the LCP index you were inspecting\n",
        "idx1 = int_suffix_array[i]       # SA[0] == 3\n",
        "idx2 = int_suffix_array[i+1]     # SA[1] == 0\n",
        "\n",
        "print(\"suffix1:\", int_inp[idx1:].tolist())  # [1, 2]\n",
        "print(\"suffix2:\", int_inp[idx2:].tolist())  # [1, 2, 3, 1, 2]\n",
        "print(\"lcp[0]  :\", int_lcp_array[0])        # 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_C3iiGzwbv1",
        "outputId": "f5c90c77-9ca3-406d-d2a1-bc41b9424b58"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydivsufsort import divsufsort, kasai\n",
        "\n",
        "string_inp = \"banana$\"\n",
        "string_suffix_array = divsufsort(string_inp)\n",
        "string_lcp_array = kasai(string_inp, string_suffix_array)\n",
        "print(string_suffix_array, string_lcp_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vErowIiPwygv",
        "outputId": "bd593ef8-77a4-457a-e58f-86237cb93497"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 5 3 1 0 4 2] [0 1 3 0 0 2 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydivsufsort import divsufsort, kasai\n",
        "\n",
        "string_inp        = \"banana$\"\n",
        "SA                = divsufsort(string_inp)\n",
        "LCP               = kasai(string_inp, SA)\n",
        "\n",
        "print(\"Suffix Array:\", SA.tolist())\n",
        "print(\"LCP Array:   \", LCP.tolist(), \"\\n\")\n",
        "\n",
        "for i in range(1, len(SA)):\n",
        "    idx1, idx2 = SA[i-1], SA[i]\n",
        "    suf1, suf2  = string_inp[idx1:], string_inp[idx2:]\n",
        "    prefix = LCP[i-1]\n",
        "    if prefix > 0:\n",
        "        assert suf1[:prefix] == suf2[:prefix]\n",
        "        print(suf1, suf2, suf1[:prefix], suf2[:prefix])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow7tz-6OxAWG",
        "outputId": "ecd3fb5c-b967-49cf-a204-a241ab320f78"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suffix Array: [6, 5, 3, 1, 0, 4, 2]\n",
            "LCP Array:    [0, 1, 3, 0, 0, 2, 0] \n",
            "\n",
            "a$ ana$ a a\n",
            "ana$ anana$ ana ana\n",
            "na$ nana$ na na\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suf1[:prefix], suf2[:prefix]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UTvaznxz9XV",
        "outputId": "46b14029-afc1-42d2-f9ab-923bb12db33b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('na', 'na')"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ETUd8E2Z1zNW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}